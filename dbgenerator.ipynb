{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a8f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 Running database generation for 6 alleles.\n",
      "✅ Loaded 20644 protein fragments from /home/benjamin-marwedel/Downloads/human_proteome.fasta.\n",
      "❌ HLA-DPA10103-DPB10101: name 'run_netmhcpan' is not defined\n",
      "❌ HLA-DPA10103-DPB10401: name 'run_netmhcpan' is not defined\n",
      "❌ HLA-DPA10103-DPB10202: name 'run_netmhcpan' is not defined\n",
      "❌ HLA-DPA10103-DPB10402: name 'run_netmhcpan' is not defined\n",
      "❌ HLA-DPA10103-DPB10201: name 'run_netmhcpan' is not defined\n",
      "❌ HLA-DPA10103-DPB10301: name 'run_netmhcpan' is not defined\n",
      "✅ All alleles processed.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os, uuid\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tempfile import NamedTemporaryFile\n",
    "import time\n",
    "import datetime\n",
    "import subprocess\n",
    "\n",
    "# User-defined configuration - edit here!\n",
    "BATCH_SIZE = 5000         # Number of peptides to process in one batch\n",
    "SPECIES = \"human\"        # or 'mouse', 'rat'\n",
    "MHC_CLASS = \"I\"          # or 'II'\n",
    "KMER_LENGTHS = [9]       # Options are 8-11 for MHC class I, 13-25 for MHC class II\n",
    "STRIDE = 1              # How many amino acids to skip between k-mers, default is 1 for full overlap\n",
    "MAX_THREADS = 6         # Number of parallel threads to use for processing\n",
    "FASTA_FILE = \"\"         # Path to the FASTA file containing protein sequences\n",
    "ALLELE_FILE = {\n",
    "    \"I\": \"\",\n",
    "    \"II\": \"\"\n",
    "}   # Paths to allele files for MHC class I and II, respectively\n",
    "\n",
    "#Optional to edit:\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"hostdb\", SPECIES, f\"mhc{MHC_CLASS}\")  #This calls the output directory based on species and MHC class; you can change this if you want to.\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Do not edit below this line unless you know what you're doing!\n",
    "\n",
    "# Helper functions!\n",
    "\n",
    "# Converts allele names into a safe file-friendly format (e.g., HLA-A*02:01 → HLA-A0201)\n",
    "def normalize_allele_format(allele):\n",
    "    safe_name = allele.replace(\"*\", \"\").replace(\":\", \"\").replace(\"/\", \"-\")\n",
    "    return safe_name\n",
    "\n",
    "def load_alleles_from_file(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            raw_alleles = [\n",
    "                line.strip() for line in f \n",
    "                if line.strip() and not line.startswith('#')\n",
    "            ]\n",
    "        # Normalize and deduplicate\n",
    "        normalized = set()\n",
    "        for allele in raw_alleles:\n",
    "            norm = normalize_allele_format(allele)\n",
    "            normalized.add(norm)\n",
    "        return sorted(normalized)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "        return []\n",
    "    \n",
    "def generate_kmers(seq, kmer_lengths, stride):\n",
    "    for k in kmer_lengths:\n",
    "        for i in range(0, len(seq) - k + 1, stride):\n",
    "            yield seq[i:i+k]\n",
    "\n",
    "# Runs NetMHCpan or NetMHCIIpan using subprocess and checks for errors\n",
    "def run_netmhcpan(peptide_file, alleles, output_file, mhc_class='I'):\n",
    "    if mhc_class == 'I':\n",
    "        cmd = [\n",
    "            \"netMHCpan\", \"-p\", peptide_file,\n",
    "            \"-a\", \",\".join(alleles), \"-BA\", \"-xls\", \"-xlsfile\", output_file\n",
    "        ]\n",
    "    elif mhc_class == 'II':\n",
    "        cmd = [\n",
    "            \"netMHCIIpan\", \"-f\", peptide_file,\n",
    "            \"-a\", \",\".join(alleles), \"-inptype\", \"1\", \"-xls\", \"-xlsfile\", output_file\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported MHC class\")\n",
    "\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    # Raise error if NetMHC failed\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(\n",
    "            f\"NetMHC command failed.\\n\"\n",
    "            f\"Command: {' '.join(cmd)}\\n\"\n",
    "            f\"Stdout:\\n{result.stdout.decode()}\\n\"\n",
    "            f\"Stderr:\\n{result.stderr.decode()}\"\n",
    "        )\n",
    "\n",
    "    # Check that output file was actually created\n",
    "    if not os.path.exists(output_file):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Expected output file not found: {output_file}\\n\"\n",
    "            f\"Command: {' '.join(cmd)}\\n\"\n",
    "            f\"Stdout:\\n{result.stdout.decode()}\\n\"\n",
    "            f\"Stderr:\\n{result.stderr.decode()}\"\n",
    "        )\n",
    "\n",
    "def process_peptide_batch(peptide_protein_pairs, allele):\n",
    "    all_hits = []\n",
    "    \n",
    "    try:\n",
    "        with NamedTemporaryFile(mode='w', suffix='.pep', delete=False) as temp:\n",
    "            for p, _ in peptide_protein_pairs:\n",
    "                temp.write(p + '\\n')\n",
    "            pep_file = temp.name\n",
    "\n",
    "        out_file = f\"/tmp/hostdb_{uuid.uuid4().hex}.xls\"\n",
    "        run_netmhcpan(pep_file, [allele], out_file, MHC_CLASS)\n",
    "\n",
    "        df = pd.read_csv(out_file, sep='\\t', skiprows=1)\n",
    "        rank_col = 'BA_Rank' if 'BA_Rank' in df.columns else 'Rank'\n",
    "        df = df[['Peptide', rank_col]].dropna()\n",
    "        df['rank'] = df[rank_col]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            peptide = row['Peptide']\n",
    "            rank = row['rank']\n",
    "            # Find the associated protein\n",
    "            protein_id = next((pid for p, pid in peptide_protein_pairs if p == peptide), \"unknown\")\n",
    "\n",
    "            record = {\n",
    "                'peptide': peptide,\n",
    "                'rank': rank,\n",
    "                'allele': allele,\n",
    "                'protein': protein_id,\n",
    "                'length': len(peptide)\n",
    "            }\n",
    "\n",
    "            all_hits.append(record)\n",
    "\n",
    "    finally:\n",
    "        for f in [pep_file, out_file]:\n",
    "            if f and os.path.exists(f):\n",
    "                os.remove(f)\n",
    "\n",
    "    return all_hits\n",
    "\n",
    "# Main script starts here\n",
    "\n",
    "# Load all alleles\n",
    "all_alleles_raw = load_alleles_from_file(ALLELE_FILE[MHC_CLASS])\n",
    "\n",
    "# Filter by species\n",
    "if SPECIES == \"human\":\n",
    "    all_alleles = [a for a in all_alleles_raw if a.startswith(\"HLA-\")]\n",
    "elif SPECIES == \"mouse\":\n",
    "    all_alleles = [a for a in all_alleles_raw if a.startswith(\"H-2-\")]\n",
    "else:\n",
    "    raise ValueError(f\"Unknown species: {SPECIES}\")\n",
    "\n",
    "print(f\"🧬 Running database generation for {len(all_alleles)} alleles.\")\n",
    "\n",
    "# seen peptide dictionary\n",
    "seen_peptides_by_allele = defaultdict(set)\n",
    "\n",
    "# Preprocess FASTA proteins once\n",
    "\n",
    "# Split at any ambiguous amino acid (X, B, Z, J, U, O)\n",
    "ambiguous_split_pattern = re.compile(r\"[XBZJUO]\")\n",
    "all_proteins = []\n",
    "\n",
    "for record in SeqIO.parse(FASTA_FILE, \"fasta\"):\n",
    "    raw_seq = str(record.seq).upper()\n",
    "    fragments = ambiguous_split_pattern.split(raw_seq)\n",
    "    for idx, frag in enumerate(fragments):\n",
    "        frag = frag.strip()\n",
    "        if len(frag) >= min(KMER_LENGTHS):  # Only store valid-length chunks\n",
    "            frag_id = f\"{record.id}_frag{idx}\"\n",
    "            all_proteins.append((frag_id, frag))\n",
    "print(f\"✅ Loaded {len(all_proteins)} protein fragments from {FASTA_FILE}.\")\n",
    "\n",
    "\n",
    "# This function will process all proteins for a given allele\n",
    "\n",
    "def process_allele(allele):\n",
    "    num_hits = 0\n",
    "    batch_peptides = []\n",
    "    safe_allele_name = allele.replace(\"*\", \"\").replace(\":\", \"\").replace(\"/\", \"-\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{safe_allele_name}_hits.csv\")\n",
    "    num_proteins = len(all_proteins)\n",
    "    protein_so_far = 0\n",
    "    batches = 0\n",
    "    start_time = time.time()\n",
    "    for protein_id, sequence in all_proteins:\n",
    "        local_seen = set()\n",
    "        new_peptides = []\n",
    "        protein_so_far += 1\n",
    "        if protein_so_far % 100 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            time_left = (elapsed / protein_so_far) * (num_proteins - protein_so_far)\n",
    "            eta = datetime.timedelta(seconds=int(time_left))\n",
    "            print(f\"Processed {protein_so_far}/{num_proteins} proteins for {allele}... ETA: {eta}\")\n",
    "        for p in generate_kmers(sequence, KMER_LENGTHS, STRIDE):\n",
    "            if p not in seen_peptides_by_allele[allele] and p not in local_seen and p not in batch_peptides:\n",
    "                new_peptides.append(p)\n",
    "                local_seen.add(p)\n",
    "\n",
    "        for p in new_peptides:\n",
    "            batch_peptides.append((p, protein_id))\n",
    "\n",
    "        # Process in batches\n",
    "        while len(batch_peptides) >= BATCH_SIZE:\n",
    "            batch, batch_peptides = batch_peptides[:BATCH_SIZE], batch_peptides[BATCH_SIZE:]\n",
    "            new_hits = process_peptide_batch(batch, allele)\n",
    "            if new_hits:\n",
    "                batch_df = pd.DataFrame(new_hits)\n",
    "                batch_df.to_csv(output_path, mode='a', index=False, header=not os.path.exists(output_path))\n",
    "                seen_peptides_by_allele[allele].update([p for p, _ in batch])\n",
    "                num_hits += len(new_hits)\n",
    "                batches += 1\n",
    "                if batches % 10 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"Processed {batches} batches for {allele} so far.\")\n",
    "\n",
    "    # Final leftovers\n",
    "    if batch_peptides:\n",
    "        new_hits = process_peptide_batch(batch_peptides, allele)\n",
    "        if new_hits:\n",
    "                batch_df = pd.DataFrame(new_hits)\n",
    "                batch_df.to_csv(output_path, mode='a', index=False, header=not os.path.exists(output_path))\n",
    "                seen_peptides_by_allele[allele].update([p for p, _ in batch_peptides])\n",
    "                num_hits += len(new_hits)\n",
    "                batches += 1\n",
    "                print(f\"Processed final batch {batches} for {allele}.\")\n",
    "    \n",
    "    return num_hits\n",
    "\n",
    "# Main processing loop using ThreadPoolExecutor for parallel processing\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    futures = {executor.submit(process_allele, allele): allele for allele in all_alleles}\n",
    "    total = len(futures)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        allele = futures[future]\n",
    "        try:\n",
    "            hits = future.result()\n",
    "            print(f\"✅ {allele}: {hits} hits found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {allele}: {e}\")\n",
    "\n",
    "print(\"✅ All alleles processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (immunomap)",
   "language": "python",
   "name": "immunomap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
